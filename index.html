<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TEKLIFE Footwork: A Digital Musicology Study</title>
    <script src="https://d3js.org/d3.v7.min.js"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Bebas+Neue&family=Orbitron:wght@400;700;900&family=JetBrains+Mono:wght@300;400&display=swap');
        
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        :root {
            --primary: #00ff41;
            --secondary: #ff0080;
            --tertiary: #00d4ff;
            --bg-dark: #0a0a0f;
            --bg-mid: #151520;
            --bg-light: #1f1f2e;
            --text: #e0e0e8;
            --text-dim: #808090;
        }
        
        body {
            background: linear-gradient(135deg, var(--bg-dark) 0%, #0f0f1a 50%, var(--bg-dark) 100%);
            color: var(--text);
            font-family: 'JetBrains Mono', monospace;
            overflow-x: hidden;
            min-height: 100vh;
            position: relative;
        }
        
        body::before {
            content: '';
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: 
                repeating-linear-gradient(
                    0deg,
                    transparent,
                    transparent 2px,
                    rgba(0, 255, 65, 0.03) 2px,
                    rgba(0, 255, 65, 0.03) 4px
                );
            pointer-events: none;
            z-index: 1;
        }
        
        .container {
            max-width: 1800px;
            margin: 0 auto;
            padding: 40px 20px;
            position: relative;
            z-index: 2;
        }
        
        .loading {
            position: fixed;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            font-family: 'Orbitron', sans-serif;
            font-size: 2rem;
            color: var(--primary);
            z-index: 9999;
            text-align: center;
        }
        
        .loading::after {
            content: '...';
            animation: dots 1.5s infinite;
        }
        
        @keyframes dots {
            0%, 20% { content: '.'; }
            40% { content: '..'; }
            60%, 100% { content: '...'; }
        }
        
        header {
            text-align: center;
            margin-bottom: 40px;
            position: relative;
        }
        
        h1 {
            font-family: 'Orbitron', sans-serif;
            font-size: 4.5rem;
            font-weight: 900;
            letter-spacing: 8px;
            background: linear-gradient(135deg, var(--primary), var(--tertiary), var(--secondary));
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            text-transform: uppercase;
            margin-bottom: 10px;
            animation: pulse 2s ease-in-out infinite alternate;
        }
        
        @keyframes pulse {
            0% { filter: brightness(1); }
            100% { filter: brightness(1.2); }
        }
        
        .subtitle {
            font-family: 'Bebas Neue', sans-serif;
            font-size: 1.8rem;
            letter-spacing: 4px;
            color: var(--text-dim);
            text-transform: uppercase;
            margin-bottom: 10px;
        }
        
        .tagline {
            font-size: 0.9rem;
            color: var(--text-dim);
            font-style: italic;
            margin-top: 10px;
        }
        
        /* Tab Navigation */
        .tab-nav {
            display: flex;
            justify-content: center;
            gap: 10px;
            margin: 40px 0;
            flex-wrap: wrap;
        }
        
        .tab-button {
            font-family: 'Bebas Neue', sans-serif;
            font-size: 1.2rem;
            letter-spacing: 2px;
            padding: 15px 30px;
            background: var(--bg-light);
            border: 2px solid var(--text-dim);
            color: var(--text-dim);
            cursor: pointer;
            clip-path: polygon(0 0, calc(100% - 15px) 0, 100% 15px, 100% 100%, 15px 100%, 0 calc(100% - 15px));
            transition: all 0.3s ease;
        }
        
        .tab-button:hover {
            border-color: var(--primary);
            color: var(--primary);
            transform: translateY(-2px);
        }
        
        .tab-button.active {
            background: var(--primary);
            color: var(--bg-dark);
            border-color: var(--primary);
            box-shadow: 0 0 20px rgba(0, 255, 65, 0.5);
        }
        
        .tab-content {
            display: none;
        }
        
        .tab-content.active {
            display: block;
            animation: fadeIn 0.5s ease;
        }
        
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(20px); }
            to { opacity: 1; transform: translateY(0); }
        }
        
        /* About Section */
        .about-section {
            background: var(--bg-mid);
            border-left: 4px solid var(--primary);
            padding: 40px;
            margin-bottom: 40px;
            line-height: 1.8;
        }
        
        .about-section h2 {
            font-family: 'Bebas Neue', sans-serif;
            font-size: 2rem;
            color: var(--primary);
            margin-bottom: 20px;
            letter-spacing: 3px;
        }
        
        .about-section h3 {
            font-family: 'Bebas Neue', sans-serif;
            font-size: 1.5rem;
            color: var(--tertiary);
            margin-top: 30px;
            margin-bottom: 15px;
            letter-spacing: 2px;
        }
        
        .about-section p {
            margin-bottom: 15px;
            font-size: 0.95rem;
        }
        
        .about-section ul {
            margin-left: 30px;
            margin-bottom: 15px;
        }
        
        .about-section li {
            margin-bottom: 8px;
            font-size: 0.95rem;
        }
        
        .research-question {
            background: var(--bg-dark);
            border: 2px solid var(--secondary);
            padding: 25px;
            margin: 20px 0;
            font-size: 1.1rem;
            font-style: italic;
            color: var(--secondary);
            clip-path: polygon(0 0, calc(100% - 20px) 0, 100% 20px, 100% 100%, 20px 100%, 0 calc(100% - 20px));
        }
        
        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin-bottom: 60px;
        }
        
        .stat-card {
            background: var(--bg-light);
            border: 2px solid var(--primary);
            padding: 20px;
            clip-path: polygon(0 0, calc(100% - 20px) 0, 100% 20px, 100% 100%, 20px 100%, 0 calc(100% - 20px));
            transition: all 0.3s ease;
        }
        
        .stat-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 30px rgba(0, 255, 65, 0.3);
        }
        
        .stat-value {
            font-family: 'Orbitron', sans-serif;
            font-size: 2.5rem;
            font-weight: 900;
            color: var(--primary);
            line-height: 1;
            margin-bottom: 5px;
        }
        
        .stat-label {
            font-size: 0.75rem;
            color: var(--text-dim);
            text-transform: uppercase;
            letter-spacing: 2px;
        }
        
        .viz-section {
            background: var(--bg-mid);
            border-left: 4px solid var(--primary);
            padding: 40px;
            margin-bottom: 40px;
            position: relative;
            overflow: hidden;
        }
        
        .viz-section::before {
            content: '';
            position: absolute;
            top: 0;
            right: 0;
            width: 200px;
            height: 200px;
            background: radial-gradient(circle, var(--primary) 0%, transparent 70%);
            opacity: 0.05;
            pointer-events: none;
        }
        
        .viz-title {
            font-family: 'Bebas Neue', sans-serif;
            font-size: 2rem;
            letter-spacing: 3px;
            color: var(--primary);
            margin-bottom: 10px;
            text-transform: uppercase;
        }
        
        .viz-description {
            font-size: 0.9rem;
            color: var(--text-dim);
            margin-bottom: 20px;
            line-height: 1.6;
        }
        
        .interpretation-box {
            background: var(--bg-dark);
            border-left: 3px solid var(--tertiary);
            padding: 20px;
            margin-top: 20px;
            font-size: 0.9rem;
            line-height: 1.7;
        }
        
        .interpretation-box h4 {
            color: var(--tertiary);
            font-family: 'Bebas Neue', sans-serif;
            font-size: 1.2rem;
            margin-bottom: 10px;
            letter-spacing: 2px;
        }
        
        svg {
            width: 100%;
            height: auto;
        }
        
        .axis text {
            font-family: 'JetBrains Mono', monospace;
            font-size: 10px;
            fill: var(--text-dim);
        }
        
        .axis line, .axis path {
            stroke: var(--text-dim);
            stroke-width: 1;
        }
        
        .grid line {
            stroke: var(--text-dim);
            stroke-opacity: 0.1;
            stroke-dasharray: 2,2;
        }
        
        .tooltip {
            position: absolute;
            padding: 12px 16px;
            background: var(--bg-dark);
            border: 2px solid var(--primary);
            border-radius: 0;
            font-size: 11px;
            pointer-events: none;
            opacity: 0;
            transition: opacity 0.2s;
            z-index: 1000;
            clip-path: polygon(0 0, calc(100% - 10px) 0, 100% 10px, 100% 100%, 10px 100%, 0 calc(100% - 10px));
        }
        
        .tooltip-title {
            font-weight: bold;
            color: var(--primary);
            margin-bottom: 5px;
        }
        
        .legend {
            font-size: 11px;
            font-family: 'JetBrains Mono', monospace;
        }
        
        @media (max-width: 768px) {
            h1 {
                font-size: 2.5rem;
                letter-spacing: 4px;
            }
            .subtitle {
                font-size: 1.2rem;
            }
            .tab-button {
                font-size: 1rem;
                padding: 12px 20px;
            }
            .viz-section, .about-section {
                padding: 20px;
            }
        }
    </style>
</head>
<body>
    <div class="loading" id="loading">LOADING DATA</div>
    <div class="container" id="container" style="opacity: 0;">
        <header>
            <h1>TEKLIFE</h1>
            <div class="subtitle">A Digital Musicology Study</div>
            <div class="tagline">Computational Analysis of Chicago Footwork (2010-2025)</div>
        </header>
        
        <!-- Tab Navigation -->
        <div class="tab-nav">
            <button class="tab-button active" onclick="switchTab('about')">About</button>
            <button class="tab-button" onclick="switchTab('overview')">Dataset Overview</button>
            <button class="tab-button" onclick="switchTab('rhythm')">Rhythm & Tempo</button>
            <button class="tab-button" onclick="switchTab('spectral')">Spectral Features</button>
            <button class="tab-button" onclick="switchTab('timbre')">Timbre & Harmony</button>
            <button class="tab-button" onclick="switchTab('texture')">Texture & Dynamics</button>
            <button class="tab-button" onclick="switchTab('context')">Cultural Context</button>
        </div>
        
        <!-- About Tab -->
        <div id="about-tab" class="tab-content active">
            <div class="about-section">
                <h2>Research Inquiry</h2>
                <div class="research-question">
                    What makes a track identifiable as "footwork," and what can digital musicology tools reveal about those defining traits?
                </div>
                
                <p>This project applies computational methods to explore footwork—a fast-paced electronic dance music genre originating from Chicago's South and West sides. Rather than producing a single definitive claim about the genre, this work foregrounds <strong>exploratory analysis</strong>, using computation to surface tendencies, clusters, gaps, and questions that can be interpreted alongside listening and historical context.</p>
                
                <h3>What is Digital Musicology?</h3>
                <p>Digital musicology applies computational methods to musical analysis, treating sound as data that can be quantified, visualized, and compared. This project extracts statistical features from audio recordings—describing rhythm, brightness, texture, harmony, and dynamics—to create a "sonic fingerprint" for each track.</p>
                
                <p>However, these features do not describe musical <em>meaning</em> directly. Instead, they provide measurable dimensions that become meaningful through interpretation. Genre identity emerges not from any single metric, but through patterns across multiple interacting dimensions.</p>
                
                <h3>Methodology</h3>
                <p>This study analyzes <strong>208 tracks</strong> from the Teklife label and associated artists, spanning 2010-2025. The dataset was constructed through:</p>
                <ul>
                    <li><strong>Data Collection:</strong> YouTube playlists labeled as Teklife/footwork, downloaded using yt-dlp and ffmpeg</li>
                    <li><strong>Feature Extraction:</strong> Audio analysis using Librosa (Python) to extract tempo, spectral characteristics, MFCCs, chroma, onset strength, and more</li>
                    <li><strong>Metadata Integration:</strong> YouTube metrics (views, likes, upload dates) to contextualize sonic features within platform circulation</li>
                    <li><strong>Iterative Cleaning:</strong> Manual listening combined with computational outlier detection to refine the dataset</li>
                </ul>
                
                <h3>Feature Categories</h3>
                <p>The extracted features characterize tracks across multiple dimensions:</p>
                <ul>
                    <li><strong>Form:</strong> Duration, tempo (BPM), beat count</li>
                    <li><strong>Rhythm:</strong> Onset strength (rhythmic intensity), beat tracking</li>
                    <li><strong>Brightness & Texture:</strong> Spectral centroid, rolloff, bandwidth</li>
                    <li><strong>Noisiness & Percussiveness:</strong> Zero-crossing rate, spectral contrast</li>
                    <li><strong>Dynamics:</strong> RMS energy</li>
                    <li><strong>Timbre:</strong> Mel-frequency cepstral coefficients (MFCCs)</li>
                    <li><strong>Harmony:</strong> Chroma features (pitch class distribution)</li>
                </ul>
                
                <h3>Key Findings</h3>
                <p>Computational analysis reveals footwork as characterized by:</p>
                <ul>
                    <li><strong>Tempo ambiguity:</strong> Peaks at ~80 BPM (half-time) and ~160 BPM (true footwork tempo)</li>
                    <li><strong>Brightness:</strong> High spectral centroids (2000-4000 Hz), indicating energetic high-frequency content</li>
                    <li><strong>Rhythmic intensity:</strong> Strong onset strength values (1.0-2.5), reflecting aggressive, syncopated beats</li>
                    <li><strong>Timbral diversity:</strong> Wide MFCC dispersion shows stylistic variety within the genre</li>
                    <li><strong>Percussive texture:</strong> High zero-crossing rates indicate noisy, percussive elements</li>
                    <li><strong>Minimal harmonic content:</strong> Lower chroma values suggest rhythm-first production</li>
                </ul>
                
                <h3>Limitations & Reflexivity</h3>
                <p>This project acknowledges several constraints:</p>
                <ul>
                    <li><strong>Platform bias:</strong> YouTube availability shapes what gets analyzed; gaps in the archive (2012-2020) reflect uneven digitization, not production gaps</li>
                    <li><strong>Teklife focus:</strong> Centering one label privileges a historically significant lineage but excludes parallel scenes</li>
                    <li><strong>Feature selection:</strong> Librosa prioritizes computationally convenient features, potentially missing embodied, social, and cultural dimensions</li>
                    <li><strong>Interpretation required:</strong> No visualization "proves" what footwork is—all require listening, context, and subjective judgment</li>
                </ul>
                
                <h3>Contributions</h3>
                <p>Rather than defining footwork definitively, this project demonstrates <strong>how digital musicology participates in constructing genre knowledge</strong>. It shows both what computation can reveal about footwork and where its explanatory power reaches its limits. The visualizations function as tools for pattern recognition, inviting further listening and contextual research rather than replacing them.</p>
                
                <p>This work contributes to ongoing conversations about applying computational methods to vernacular electronic music, highlighting the importance of reflexivity about data sources, feature choices, and interpretive framing.</p>
            </div>
        </div>
        
        <!-- Dataset Overview Tab -->
        <div id="overview-tab" class="tab-content">
            <div class="stats-grid" id="stats"></div>
            
            <div class="viz-section">
                <h2 class="viz-title">Temporal Evolution: Uploads & Engagement</h2>
                <p class="viz-description">
                    Tracking how Teklife footwork has evolved on YouTube over time, showing upload frequency and audience engagement patterns from 2010 to 2025. The timeline reveals the genre's digital circulation history.
                </p>
                <svg id="timeline-viz" viewBox="0 0 1200 500"></svg>
                <div class="interpretation-box">
                    <h4>Interpretation</h4>
                    <p>The pronounced gap between 2012 and 2020 does not reflect a decline in footwork production, but rather <strong>uneven archival practices</strong> and platform visibility. Tracks from this period exist but were not consistently labeled as "Teklife" or "footwork" in YouTube metadata, making them harder to discover systematically.</p>
                    <p>This visualization demonstrates a key limitation of platform-based musicology: <strong>what is available shapes what can be known</strong>. The dataset represents not "all footwork," but "what YouTube users labeled and uploaded as footwork."</p>
                </div>
            </div>
            
            <div class="viz-section">
                <h2 class="viz-title">Artist Network & Output</h2>
                <p class="viz-description">
                    The ecosystem of Teklife artists and channels, sized by track count and colored by average engagement. This network shows production centrality and audience reach within the digital footwork community.
                </p>
                <svg id="artist-viz" viewBox="0 0 1200 700"></svg>
                <div class="interpretation-box">
                    <h4>Interpretation</h4>
                    <p>TEKLIFE Records dominates with 124 tracks, establishing it as the central node for digital footwork circulation. However, individual artists like DJ Rashad, RP Boo, and Traxman maintain distinct presences, suggesting the label functions as an aggregator rather than sole distributor.</p>
                    <p>Engagement (measured by views) does not strictly correlate with output. Some prolific artists have modest viewcounts, while others with fewer tracks achieve higher visibility—indicating that <strong>platform algorithms and social circulation shape which tracks become canonical</strong>.</p>
                </div>
            </div>
        </div>
        
        <!-- Rhythm & Tempo Tab -->
        <div id="rhythm-tab" class="tab-content">
            <div class="viz-section">
                <h2 class="viz-title">Tempo Distribution & BPM Clustering</h2>
                <p class="viz-description">
                    Footwork music is characterized by its ~160 BPM tempo, though often detected at half-time (~80 BPM) by analysis tools. This histogram reveals the tempo clusters and rhythmic characteristics of the genre.
                </p>
                <svg id="tempo-viz" viewBox="0 0 1200 500"></svg>
                <div class="interpretation-box">
                    <h4>Interpretation</h4>
                    <p>The dual peaks at ~80 BPM and ~160 BPM reflect a fundamental challenge in computational tempo detection: <strong>footwork's syncopated rhythms can be perceived at half-speed</strong>. Librosa's beat tracking often locks onto every other beat, registering 80 BPM when the "true" footwork tempo is 160 BPM.</p>
                    <p>This finding illustrates that <strong>tempo is not a neutral measurement</strong>—it depends on which rhythmic layer the algorithm privileges. Human listeners familiar with footwork hear 160 BPM as the primary pulse, but algorithms may disagree. This reinforces that computational features require interpretive contextualization.</p>
                </div>
            </div>
            
            <div class="viz-section">
                <h2 class="viz-title">Rhythmic Intensity Distribution</h2>
                <p class="viz-description">
                    Onset strength measures rhythmic transients—the "punch" of beats. This distribution reveals how footwork tracks cluster around different rhythmic intensity profiles, from subtle to aggressive.
                </p>
                <svg id="rhythm-viz" viewBox="0 0 1200 500"></svg>
                <div class="interpretation-box">
                    <h4>Interpretation</h4>
                    <p>The distribution centers around onset strength values of 1.0-2.5, indicating <strong>consistently high rhythmic intensity</strong> across the dataset. This aligns with footwork's reputation for aggressive, percussive production.</p>
                    <p>However, some tracks show lower onset strength despite clearly being footwork. This suggests that <strong>rhythmic intensity alone cannot define the genre</strong>—tracks can be recognizably footwork while varying in percussive attack. Genre identity emerges through combinations of features rather than single thresholds.</p>
                </div>
            </div>
        </div>
        
        <!-- Spectral Features Tab -->
        <div id="spectral-tab" class="tab-content">
            <div class="viz-section">
                <h2 class="viz-title">Sonic Fingerprint: Spectral Characteristics</h2>
                <p class="viz-description">
                    Each track's spectral centroid (brightness) vs. RMS energy reveals the sonic signature of footwork—bright, energetic, and dynamic. Size indicates onset strength (rhythmic intensity), color shows tempo clustering.
                </p>
                <svg id="spectral-viz" viewBox="0 0 1200 600"></svg>
                <div class="interpretation-box">
                    <h4>Interpretation</h4>
                    <p>Footwork tracks cluster in the <strong>high brightness, high energy</strong> region of this space. Spectral centroids between 2000-4000 Hz indicate that most energy resides in the upper-mid to high frequencies, creating the genre's characteristic "bright" sonic profile.</p>
                    <p>Combined with high RMS energy, this suggests footwork prioritizes <strong>loud, aggressive, high-frequency content</strong>. The tight clustering validates computational analysis: footwork is legible as a genre through these spectral features. However, outliers exist—some tracks with lower brightness or energy are still recognizably footwork, suggesting that spectral characteristics alone are insufficient for genre classification.</p>
                </div>
            </div>
            
            <div class="viz-section">
                <h2 class="viz-title">Spectral Profile: Bandwidth vs. Rolloff</h2>
                <p class="viz-description">
                    Spectral bandwidth and rolloff reveal frequency distribution. Rolloff indicates the frequency below which 85% of energy is contained. Together they show the "width" and "weight" of each track's frequency spectrum.
                </p>
                <svg id="spectral-profile-viz" viewBox="0 0 1200 600"></svg>
                <div class="interpretation-box">
                    <h4>Interpretation</h4>
                    <p>High spectral rolloff values (4000-8000 Hz) confirm that footwork's energy extends well into the high frequencies, supporting the "brightness" finding. Combined with wide spectral bandwidth, this indicates <strong>dense, full-spectrum production</strong> that occupies a broad frequency range.</p>
                    <p>This differs from bass-focused genres like dubstep or drum and bass, where rolloff would be lower. Footwork's spectral profile suggests <strong>high-frequency percussion and synth elements dominate</strong>, rather than sub-bass emphasis. This aligns with the genre's dancefloor function—prioritizing rhythmic clarity and treble punch over low-end weight.</p>
                </div>
            </div>
            
            <div class="viz-section">
                <h2 class="viz-title">Feature Correlation Matrix</h2>
                <p class="viz-description">
                    Exploring relationships between audio features to understand what makes footwork distinctive: tempo, spectral characteristics, and rhythmic properties. Correlation values reveal which features move together.
                </p>
                <svg id="correlation-viz" viewBox="0 0 1000 1000"></svg>
                <div class="interpretation-box">
                    <h4>Interpretation</h4>
                    <p>Strong positive correlation between <strong>brightness (spectral centroid) and onset strength</strong> suggests that brighter tracks tend to have more rhythmic punch. This makes sense: high-frequency percussion creates both brightness and strong transients.</p>
                    <p>Weak correlation between <strong>tempo and most other features</strong> indicates that BPM alone does not determine sonic characteristics. Tracks at 80 BPM and 160 BPM can have similar brightness, energy, and rhythmic profiles—reinforcing that the half-time detection issue does not fundamentally alter the track's sonic fingerprint.</p>
                    <p>Near-zero correlation between <strong>view count and most audio features</strong> shows that popularity is not determined by sonic experimentation or any single characteristic. Platform success depends on factors beyond computational features—artist reputation, release timing, algorithmic recommendation, and social circulation.</p>
                </div>
            </div>
        </div>
        
        <!-- Timbre & Harmony Tab -->
        <div id="timbre-tab" class="tab-content">
            <div class="viz-section">
                <h2 class="viz-title">MFCC Timbre Space</h2>
                <p class="viz-description">
                    Mel-Frequency Cepstral Coefficients reveal timbral characteristics. The first two MFCCs capture the overall spectral shape—a sonic fingerprint of each track's texture and tone.
                </p>
                <svg id="mfcc-viz" viewBox="0 0 1200 600"></svg>
                <div class="interpretation-box">
                    <h4>Interpretation</h4>
                    <p>Unlike the tight clustering seen in spectral brightness and energy, MFCCs show <strong>wide dispersion</strong> across the feature space. This suggests that <strong>timbre is not a genre-defining characteristic of footwork</strong>—tracks can sound texturally different while remaining recognizably footwork.</p>
                    <p>This timbral diversity reflects footwork's sampling practices and production approaches. Some tracks use vocal chops, others emphasize synth stabs, still others rely on heavily processed percussion. What unifies them is <strong>not timbral similarity, but rhythmic and structural conventions</strong>.</p>
                    <p>This finding is methodologically important: it shows that computational features capture different aspects of genre identity. Some dimensions (brightness, rhythm) cluster tightly; others (timbre) remain heterogeneous. Genre is not reducible to a single measurable trait.</p>
                </div>
            </div>
            
            <div class="viz-section">
                <h2 class="viz-title">Harmonic Complexity: Chroma Analysis</h2>
                <p class="viz-description">
                    Chroma features capture pitch class distribution. Higher values indicate more harmonic content, while variation (std) shows harmonic complexity and movement throughout tracks.
                </p>
                <svg id="chroma-viz" viewBox="0 0 1200 500"></svg>
                <div class="interpretation-box">
                    <h4>Interpretation</h4>
                    <p>Footwork shows <strong>relatively low chroma values</strong> compared to melody-forward genres, indicating minimal harmonic content. Most tracks prioritize rhythm and percussion over pitched melodic material.</p>
                    <p>However, variation exists—some tracks show higher chroma means, suggesting occasional use of sustained harmonic elements (pads, bass lines, vocal samples). This supports the understanding that footwork is <strong>rhythm-first</strong>, but not rhythm-only.</p>
                    <p>The low harmonic complexity aligns with the genre's dancefloor function: <strong>clarity of rhythm matters more than harmonic progression</strong>. Footwork dancers respond to beat patterns, syncopation, and rhythmic breaks rather than chord changes.</p>
                </div>
            </div>
            
            <div class="viz-section">
                <h2 class="viz-title">Multi-Dimensional Feature Space</h2>
                <p class="viz-description">
                    Parallel coordinates visualization showing how multiple audio features relate across tracks. Each line represents a track, colored by tempo. Patterns reveal the multi-dimensional signature of footwork.
                </p>
                <svg id="parallel-viz" viewBox="0 0 1200 700"></svg>
                <div class="interpretation-box">
                    <h4>Interpretation</h4>
                    <p>This visualization demonstrates that <strong>footwork cannot be reduced to a single dimension</strong>. Genre identity emerges through relationships across multiple features simultaneously.</p>
                    <p>Tracks showing high values across Brightness, Energy, Onset, and ZCR form recognizable "footwork profiles"—but individual tracks deviate in specific dimensions while remaining identifiable as footwork. This suggests the genre allows stylistic variation within constraints.</p>
                    <p>The parallel coordinates view is difficult to read but methodologically important: it shows that <strong>computational genre classification requires multi-dimensional thinking</strong>. Scatter plots of two features at a time can miss relationships that only become visible when considering multiple dimensions together.</p>
                </div>
            </div>
        </div>
        
        <!-- Texture & Dynamics Tab -->
        <div id="texture-tab" class="tab-content">
            <div class="viz-section">
                <h2 class="viz-title">Texture Analysis: Zero-Crossing Rate</h2>
                <p class="viz-description">
                    Zero-crossing rate correlates with noisiness and percussive content. Higher ZCR suggests more high-frequency energy and percussive elements—key characteristics of footwork's aggressive sound design.
                </p>
                <svg id="zcr-viz" viewBox="0 0 1200 600"></svg>
                <div class="interpretation-box">
                    <h4>Interpretation</h4>
                    <p>Footwork shows <strong>elevated ZCR values</strong> compared to many electronic genres, indicating high levels of noisy, percussive content. This aligns with the genre's emphasis on snares, hi-hats, and heavily processed drum samples.</p>
                    <p>The correlation between ZCR and spectral bandwidth suggests that tracks with more high-frequency noise also tend to occupy a wider frequency range. This creates the characteristic <strong>"dense, chaotic" texture</strong> that defines footwork's sonic aesthetic.</p>
                    <p>However, some tracks maintain footwork's rhythmic structure while showing lower ZCR—suggesting that percussive density is typical but not obligatory. The genre's definition remains flexible within certain constraints.</p>
                </div>
            </div>
            
            <div class="viz-section">
                <h2 class="viz-title">Popularity vs. Sonic Innovation</h2>
                <p class="viz-description">
                    Does sonic experimentation (measured by spectral variance) correlate with engagement? Exploring the relationship between creative risk and audience response.
                </p>
                <svg id="innovation-viz" viewBox="0 0 1200 500"></svg>
                <div class="interpretation-box">
                    <h4>Interpretation</h4>
                    <p>The weak correlation between spectral variance and view count suggests that <strong>sonic experimentation does not predict popularity</strong> on YouTube. Tracks with high spectral variance (indicating dynamic, evolving frequency content) do not systematically receive more or fewer views.</p>
                    <p>This finding has two implications. First, it suggests that <strong>platform success depends on factors beyond sonic innovation</strong>—artist reputation, release context, algorithmic visibility, and social networks matter more than measurable audio characteristics.</p>
                    <p>Second, it challenges assumptions about "innovation" as a value in electronic music. Spectral variance measures one type of sonic change, but not necessarily the qualities that footwork practitioners or audiences value. Innovation might exist in rhythmic structures, sampling choices, or cultural references—dimensions that audio features cannot capture.</p>
                </div>
            </div>
        </div>
        
        <!-- Cultural Context Tab -->
        <div id="context-tab" class="tab-content">
            <div class="about-section">
                <h2>Cultural & Historical Context</h2>
                
                <h3>What is Footwork?</h3>
                <p>Footwork is a fast-paced electronic dance music genre that emerged from Chicago's South and West sides in the late 1990s and early 2000s. Characterized by syncopated kick drums, chopped samples, and tempos around 160 BPM, footwork developed alongside an equally athletic dance style of the same name.</p>
                
                <p>The genre evolved from earlier Chicago styles like ghetto house and juke, accelerating their tempos and intensifying their rhythmic complexity. Footwork tracks often feature rapid-fire drum patterns, vocal samples (frequently chopped and pitched), and sparse melodic elements, prioritizing rhythmic innovation over harmonic development.</p>
                
                <h3>Teklife: The Collective</h3>
                <p>Teklife (originally stylized as "TEK.LIF3") is a Chicago-based music collective, record label, and cultural movement. Formed officially around 2011 from the earlier Ghettoteknitianz crew, Teklife played a central role in globalizing footwork beyond its local origins.</p>
                
                <p>Key members have included DJ Rashad, DJ Spinn, RP Boo, DJ Manny, DJ Earl, Traxman, and many others. The collective's releases on labels like Hyperdub and Planet Mu introduced footwork to international electronic music audiences, establishing it as a recognized genre within broader dance music contexts.</p>
                
                <p>Teklife represents both a specific lineage within footwork and a brand that has become synonymous with the genre itself for many international listeners. This dual role—as scene participant and genre ambassador—makes it a compelling but incomplete lens for understanding footwork broadly.</p>
                
                <h3>Why Focus on Teklife?</h3>
                <p>This project centers on Teklife for several reasons:</p>
                <ul>
                    <li><strong>Historical Significance:</strong> Teklife is widely recognized as central to footwork's development and global circulation</li>
                    <li><strong>Data Availability:</strong> Teklife tracks are consistently labeled and widely available on YouTube, making systematic collection feasible</li>
                    <li><strong>Coherent Corpus:</strong> Focusing on one collective provides stylistic and social coherence, reducing the noisiness that would come from aggregating disparate sources</li>
                    <li><strong>Practical Constraints:</strong> A broader survey of all footwork production would be impractical within this project's scope</li>
                </ul>
                
                <p>However, this focus introduces important limitations. Teklife represents a <strong>specific lineage and aesthetic within footwork</strong>, not the entire genre. Parallel scenes, independent producers, and regional variations exist outside this dataset. Any conclusions drawn here apply primarily to Teklife-associated production, not footwork universally.</p>
                
                <h3>Digital Circulation & Platform Bias</h3>
                <p>Studying footwork through YouTube introduces platform-specific distortions. YouTube is not a neutral archive—it reflects:</p>
                <ul>
                    <li><strong>Upload decisions:</strong> Who chose to upload which tracks, and how they labeled them</li>
                    <li><strong>Copyright enforcement:</strong> Some tracks may have been removed, creating gaps</li>
                    <li><strong>Algorithmic visibility:</strong> Recommended videos and search results shape which tracks accumulate views</li>
                    <li><strong>Temporal lag:</strong> Older tracks may have been uploaded later, distorting chronological patterns</li>
                </ul>
                
                <p>The pronounced gap in this dataset between 2012-2020 reflects not a production decline, but <strong>uneven digitization practices</strong>. Tracks from this period exist but were not consistently labeled or uploaded to YouTube in ways that made them discoverable through systematic search.</p>
                
                <p>This is a fundamental limitation of platform-based musicology: <strong>what is available shapes what can be known</strong>. The dataset represents "what YouTube users labeled and uploaded as Teklife/footwork," not "all Teklife/footwork production."</p>
                
                <h3>Methodological Reflexivity</h3>
                <p>This project acknowledges that <strong>computational analysis constructs rather than discovers genre</strong>. Every methodological choice shapes the findings:</p>
                <ul>
                    <li><strong>Feature selection:</strong> Librosa prioritizes features that are computationally convenient (spectral, rhythmic, timbral) while eliding social, embodied, and cultural dimensions</li>
                    <li><strong>Visualization choices:</strong> Deciding which features to plot together, which color scales to use, and how to label axes all influence interpretation</li>
                    <li><strong>Dataset boundaries:</strong> Centering Teklife excludes parallel footwork scenes and independent producers</li>
                    <li><strong>Platform mediation:</strong> YouTube metadata (views, likes) measures platform engagement, not dancefloor response or local cultural significance</li>
                </ul>
                
                <p>Rather than undermining the project, these constraints clarify its contribution: demonstrating <strong>how digital musicology methods participate in constructing genre knowledge</strong>, revealing both their affordances and limitations.</p>
                
                <h3>Conclusions: What Computation Reveals (and Obscures)</h3>
                <p>This study confirms that computational tools can meaningfully surface sonic tendencies within footwork:</p>
                <ul>
                    <li>High rhythmic intensity (onset strength)</li>
                    <li>Bright spectral profiles (high-frequency emphasis)</li>
                    <li>Tempo ambiguity (half-time detection issues)</li>
                    <li>Timbral diversity (no single "footwork sound")</li>
                    <li>Minimal harmonic content (rhythm-first production)</li>
                    <li>Percussive texture (high zero-crossing rates)</li>
                </ul>
                
                <p>However, these tendencies become legible as "footwork characteristics" only through interpretation paired with listening and contextual knowledge. <strong>No single metric defines the genre</strong>—instead, genre identity emerges through clusters, relationships, and outliers across multiple dimensions simultaneously.</p>
                
                <p>What computation cannot capture:</p>
                <ul>
                    <li>Social and cultural meanings embedded in sampling choices</li>
                    <li>Embodied knowledge from dancing to footwork</li>
                    <li>Local scene histories and personal relationships between producers</li>
                    <li>How tracks function in specific dancefloor or listening contexts</li>
                    <li>The affective and experiential dimensions of the music</li>
                </ul>
                
                <p>This project ultimately answers the research question <strong>partially and reflexively</strong>: it shows both what computational methods can reveal about footwork's sonic fingerprint and where their explanatory power reaches its limits. Genre knowledge requires multiple modes of engagement—listening, reading, attending events, and yes, computing—no single method is sufficient alone.</p>
            </div>
        </div>
    </div>
    
    <footer style="text-align: center; padding: 40px 20px; color: var(--text-dim); font-size: 0.85rem; border-top: 1px solid var(--text-dim); margin-top: 60px; opacity: 0.6;">
        <p style="margin-bottom: 10px;">
            <strong style="color: var(--primary);">TEKLIFE FOOTWORK: A DIGITAL MUSICOLOGY STUDY</strong>
        </p>
        <p style="margin-bottom: 5px;">
            Audio features extracted using Librosa • Metadata from YouTube • 208 tracks analyzed (2010-2025)
        </p>
        <p>
            Visualizations built with D3.js v7 • Click on data points to explore tracks on YouTube
        </p>
    </footer>
    
    <div class="tooltip" id="tooltip"></div>
    
    <script>
        // Tab switching function
        function switchTab(tabName) {
            // Hide all tab contents
            const tabs = document.querySelectorAll('.tab-content');
            tabs.forEach(tab => tab.classList.remove('active'));
            
            // Remove active class from all buttons
            const buttons = document.querySelectorAll('.tab-button');
            buttons.forEach(button => button.classList.remove('active'));
            
            // Show selected tab
            document.getElementById(tabName + '-tab').classList.add('active');
            
            // Add active class to clicked button
            event.target.classList.add('active');
            
            // Scroll to top
            window.scrollTo({ top: 0, behavior: 'smooth' });
        }
        
        // Load and process data
        Promise.all([
            d3.json('yt_clean_analysis.json'),
            d3.json('yt_clean_metadata.json')
        ]).then(([analysisData, metadataData]) => {
            // Merge datasets
            const data = analysisData.map((analysis, i) => ({
                ...analysis,
                ...metadataData[i],
                date: parseDate(metadataData[i].upload_date),
                engagement: metadataData[i].view_count + (metadataData[i].like_count * 10),
                spectral_variance: analysis.spectral_centroid_std / analysis.spectral_centroid_mean
            }));
            
            function parseDate(dateStr) {
                const year = dateStr.substring(0, 4);
                const month = dateStr.substring(4, 6);
                const day = dateStr.substring(6, 8);
                return new Date(year, month - 1, day);
            }
            
            // Calculate statistics
            const stats = {
                totalTracks: data.length,
                avgTempo: d3.mean(data, d => d.tempo_bpm).toFixed(1),
                dateRange: `${d3.min(data, d => d.date).getFullYear()}-${d3.max(data, d => d.date).getFullYear()}`,
                totalViews: d3.sum(data, d => d.view_count),
                avgDuration: (d3.mean(data, d => d.duration_seconds) / 60).toFixed(1)
            };
            
            console.log('Data loaded:', data.length, 'tracks');
            
            // Hide loading, show content
            d3.select('#loading').style('display', 'none');
            d3.select('#container')
                .transition()
                .duration(800)
                .style('opacity', 1);
            
            renderStats(stats);
            renderTempoViz(data);
            renderTimelineViz(data);
            renderSpectralViz(data);
            renderCorrelationViz(data);
            renderArtistViz(data);
            renderInnovationViz(data);
            renderMFCCViz(data);
            renderChromaViz(data);
            renderSpectralProfileViz(data);
            renderRhythmViz(data);
            renderZCRViz(data);
            renderParallelViz(data);
        }).catch(error => {
            console.error('Error loading data:', error);
            d3.select('#loading').html('ERROR LOADING DATA<br><small style="font-size: 0.8rem;">Check console for details</small>');
        });
        
        function renderStats(stats) {
            const statsGrid = d3.select('#stats');
            const statsData = [
                { label: 'Total Tracks', value: stats.totalTracks },
                { label: 'Avg BPM', value: stats.avgTempo },
                { label: 'Years Analyzed', value: stats.dateRange },
                { label: 'Total Views', value: (stats.totalViews / 1000000).toFixed(1) + 'M' },
                { label: 'Avg Duration', value: stats.avgDuration + ' min' }
            ];
            
            const cards = statsGrid.selectAll('.stat-card')
                .data(statsData)
                .join('div')
                .attr('class', 'stat-card')
                .style('opacity', 0)
                .style('transform', 'translateY(20px)')
                .html(d => `
                    <div class="stat-value">${d.value}</div>
                    <div class="stat-label">${d.label}</div>
                `);
            
            cards.transition()
                .duration(600)
                .delay((d, i) => i * 100)
                .style('opacity', 1)
                .style('transform', 'translateY(0)');
        }
        
        // [All the rendering functions from the original code - tempo, timeline, spectral, etc.]
        // For brevity, I'll include the key ones and note that all original functions should be included
        
        function renderTempoViz(data) {
            const svg = d3.select('#tempo-viz');
            const width = 1200, height = 500;
            const margin = { top: 40, right: 40, bottom: 60, left: 70 };
            const g = svg.append('g').attr('transform', `translate(${margin.left},${margin.top})`);
            
            const x = d3.scaleLinear()
                .domain([70, 180])
                .range([0, width - margin.left - margin.right]);
            
            const histogram = d3.histogram()
                .domain(x.domain())
                .thresholds(x.ticks(40))
                .value(d => d.tempo_bpm);
            
            const bins = histogram(data);
            
            const y = d3.scaleLinear()
                .domain([0, d3.max(bins, d => d.length)])
                .range([height - margin.top - margin.bottom, 0]);
            
            g.append('g')
                .attr('class', 'grid')
                .call(d3.axisLeft(y).tickSize(-(width - margin.left - margin.right)).tickFormat(''));
            
            const gradient = svg.append('defs')
                .append('linearGradient')
                .attr('id', 'tempo-gradient')
                .attr('x1', '0%').attr('y1', '0%')
                .attr('x2', '0%').attr('y2', '100%');
            
            gradient.append('stop')
                .attr('offset', '0%')
                .attr('stop-color', '#00ff41')
                .attr('stop-opacity', 1);
            
            gradient.append('stop')
                .attr('offset', '100%')
                .attr('stop-color', '#00d4ff')
                .attr('stop-opacity', 0.6);
            
            g.selectAll('rect')
                .data(bins)
                .join('rect')
                .attr('x', d => x(d.x0) + 1)
                .attr('y', height - margin.top - margin.bottom)
                .attr('width', d => Math.max(0, x(d.x1) - x(d.x0) - 2))
                .attr('height', 0)
                .attr('fill', 'url(#tempo-gradient)')
                .attr('stroke', '#00ff41')
                .attr('stroke-width', 0.5)
                .on('mouseover', function(event, d) {
                    d3.select(this).attr('opacity', 0.7);
                    showTooltip(event, `<div class="tooltip-title">${d.x0}-${d.x1} BPM</div>
                        <div>${d.length} tracks</div>`);
                })
                .on('mouseout', function() {
                    d3.select(this).attr('opacity', 1);
                    hideTooltip();
                })
                .transition()
                .duration(1000)
                .delay((d, i) => i * 20)
                .attr('y', d => y(d.length))
                .attr('height', d => height - margin.top - margin.bottom - y(d.length));
            
            const refLines = [
                { bpm: 80, label: '80 BPM (Half-time)' },
                { bpm: 160, label: '160 BPM (True Footwork)' }
            ];
            
            refLines.forEach(ref => {
                g.append('line')
                    .attr('x1', x(ref.bpm))
                    .attr('x2', x(ref.bpm))
                    .attr('y1', 0)
                    .attr('y2', height - margin.top - margin.bottom)
                    .attr('stroke', '#ff0080')
                    .attr('stroke-width', 2)
                    .attr('stroke-dasharray', '5,5')
                    .attr('opacity', 0.6);
                
                g.append('text')
                    .attr('x', x(ref.bpm))
                    .attr('y', -10)
                    .attr('text-anchor', 'middle')
                    .attr('fill', '#ff0080')
                    .attr('font-size', '10px')
                    .text(ref.label);
            });
            
            g.append('g')
                .attr('class', 'axis')
                .attr('transform', `translate(0,${height - margin.top - margin.bottom})`)
                .call(d3.axisBottom(x));
            
            g.append('g')
                .attr('class', 'axis')
                .call(d3.axisLeft(y));
            
            svg.append('text')
                .attr('x', width / 2)
                .attr('y', height - 20)
                .attr('text-anchor', 'middle')
                .attr('fill', '#e0e0e8')
                .attr('font-size', '12px')
                .text('Tempo (BPM)');
            
            svg.append('text')
                .attr('transform', 'rotate(-90)')
                .attr('x', -height / 2)
                .attr('y', 20)
                .attr('text-anchor', 'middle')
                .attr('fill', '#e0e0e8')
                .attr('font-size', '12px')
                .text('Track Count');
        }
        
        function renderTimelineViz(data) {
            const svg = d3.select('#timeline-viz');
            const width = 1200, height = 500;
            const margin = { top: 40, right: 40, bottom: 60, left: 70 };
            const g = svg.append('g').attr('transform', `translate(${margin.left},${margin.top})`);
            
            const monthlyData = d3.rollups(
                data,
                v => ({
                    count: v.length,
                    avgViews: d3.mean(v, d => d.view_count),
                    totalViews: d3.sum(v, d => d.view_count),
                    avgLikes: d3.mean(v, d => d.like_count)
                }),
                d => d3.timeMonth(d.date)
            ).map(([date, stats]) => ({ date, ...stats }))
            .sort((a, b) => a.date - b.date);
            
            const x = d3.scaleTime()
                .domain(d3.extent(monthlyData, d => d.date))
                .range([0, width - margin.left - margin.right]);
            
            const y = d3.scaleLinear()
                .domain([0, d3.max(monthlyData, d => d.count)])
                .range([height - margin.top - margin.bottom, 0]);
            
            const y2 = d3.scaleLinear()
                .domain([0, d3.max(monthlyData, d => d.avgViews)])
                .range([height - margin.top - margin.bottom, 0]);
            
            g.append('g')
                .attr('class', 'grid')
                .call(d3.axisLeft(y).tickSize(-(width - margin.left - margin.right)).tickFormat(''));
            
            const area = d3.area()
                .x(d => x(d.date))
                .y0(height - margin.top - margin.bottom)
                .y1(d => y(d.count))
                .curve(d3.curveMonotoneX);
            
            const areaGradient = svg.append('defs')
                .append('linearGradient')
                .attr('id', 'area-gradient')
                .attr('x1', '0%').attr('y1', '0%')
                .attr('x2', '0%').attr('y2', '100%');
            
            areaGradient.append('stop')
                .attr('offset', '0%')
                .attr('stop-color', '#00ff41')
                .attr('stop-opacity', 0.8);
            
            areaGradient.append('stop')
                .attr('offset', '100%')
                .attr('stop-color', '#00ff41')
                .attr('stop-opacity', 0.1);
            
            g.append('path')
                .datum(monthlyData)
                .attr('fill', 'url(#area-gradient)')
                .attr('stroke', '#00ff41')
                .attr('stroke-width', 2)
                .attr('d', area);
            
            const line = d3.line()
                .x(d => x(d.date))
                .y(d => y2(d.avgViews))
                .curve(d3.curveMonotoneX);
            
            g.append('path')
                .datum(monthlyData)
                .attr('fill', 'none')
                .attr('stroke', '#ff0080')
                .attr('stroke-width', 2)
                .attr('d', line);
            
            g.selectAll('circle')
                .data(monthlyData)
                .join('circle')
                .attr('cx', d => x(d.date))
                .attr('cy', d => y2(d.avgViews))
                .attr('r', 3)
                .attr('fill', '#ff0080')
                .attr('opacity', 0)
                .on('mouseover', function(event, d) {
                    d3.select(this).attr('r', 6).attr('opacity', 1);
                    showTooltip(event, `<div class="tooltip-title">${d3.timeFormat('%B %Y')(d.date)}</div>
                        <div>Uploads: ${d.count}</div>
                        <div>Avg Views: ${d.avgViews.toFixed(0)}</div>
                        <div>Avg Likes: ${d.avgLikes.toFixed(0)}</div>`);
                })
                .on('mouseout', function() {
                    d3.select(this).attr('r', 3).attr('opacity', 0);
                    hideTooltip();
                });
            
            g.append('g')
                .attr('class', 'axis')
                .attr('transform', `translate(0,${height - margin.top - margin.bottom})`)
                .call(d3.axisBottom(x).tickFormat(d3.timeFormat('%Y')));
            
            g.append('g')
                .attr('class', 'axis')
                .call(d3.axisLeft(y));
            
            g.append('g')
                .attr('class', 'axis')
                .attr('transform', `translate(${width - margin.left - margin.right},0)`)
                .call(d3.axisRight(y2));
            
            svg.append('text')
                .attr('x', width / 2)
                .attr('y', height - 20)
                .attr('text-anchor', 'middle')
                .attr('fill', '#e0e0e8')
                .attr('font-size', '12px')
                .text('Upload Date');
            
            svg.append('text')
                .attr('transform', 'rotate(-90)')
                .attr('x', -height / 2)
                .attr('y', 20)
                .attr('text-anchor', 'middle')
                .attr('fill', '#00ff41')
                .attr('font-size', '12px')
                .text('Upload Count');
            
            svg.append('text')
                .attr('x', width - 30)
                .attr('y', 30)
                .attr('text-anchor', 'end')
                .attr('fill', '#ff0080')
                .attr('font-size', '12px')
                .text('Avg Views');
        }
        
        function renderSpectralViz(data) {
            const svg = d3.select('#spectral-viz');
            const width = 1200, height = 600;
            const margin = { top: 40, right: 140, bottom: 60, left: 70 };
            const g = svg.append('g').attr('transform', `translate(${margin.left},${margin.top})`);
            
            const x = d3.scaleLinear()
                .domain(d3.extent(data, d => d.spectral_centroid_mean))
                .range([0, width - margin.left - margin.right])
                .nice();
            
            const y = d3.scaleLinear()
                .domain(d3.extent(data, d => d.rms_mean))
                .range([height - margin.top - margin.bottom, 0])
                .nice();
            
            const colorScale = d3.scaleSequential()
                .domain([75, 165])
                .interpolator(t => {
                    if (t < 0.5) return d3.interpolateRgb('#00d4ff', '#00ff41')(t * 2);
                    return d3.interpolateRgb('#00ff41', '#ff0080')((t - 0.5) * 2);
                });
            
            const sizeScale = d3.scaleSqrt()
                .domain(d3.extent(data, d => d.onset_strength_mean))
                .range([3, 15]);
            
            g.append('g')
                .attr('class', 'grid')
                .call(d3.axisLeft(y).tickSize(-(width - margin.left - margin.right)).tickFormat(''));
            
            g.append('g')
                .attr('class', 'grid')
                .attr('transform', `translate(0,${height - margin.top - margin.bottom})`)
                .call(d3.axisBottom(x).tickSize(-(height - margin.top - margin.bottom)).tickFormat(''));
            
            g.selectAll('circle')
                .data(data)
                .join('circle')
                .attr('cx', d => x(d.spectral_centroid_mean))
                .attr('cy', d => y(d.rms_mean))
                .attr('r', 0)
                .attr('fill', d => colorScale(d.tempo_bpm))
                .attr('fill-opacity', 0.6)
                .attr('stroke', d => colorScale(d.tempo_bpm))
                .attr('stroke-width', 1.5)
                .style('cursor', 'pointer')
                .on('mouseover', function(event, d) {
                    d3.select(this)
                        .attr('fill-opacity', 1)
                        .attr('stroke-width', 3)
                        .raise();
                    showTooltip(event, `<div class="tooltip-title">${d.title}</div>
                        <div>Artist: ${d.uploader}</div>
                        <div>BPM: ${d.tempo_bpm.toFixed(1)}</div>
                        <div>Brightness: ${d.spectral_centroid_mean.toFixed(0)} Hz</div>
                        <div>Energy: ${d.rms_mean.toFixed(3)}</div>
                        <div>Onset: ${d.onset_strength_mean.toFixed(2)}</div>
                        <div>Views: ${d.view_count.toLocaleString()}</div>
                        <div style="margin-top: 5px; color: #00d4ff; font-size: 9px;">CLICK TO OPEN ON YOUTUBE</div>`);
                })
                .on('mouseout', function() {
                    d3.select(this)
                        .attr('fill-opacity', 0.6)
                        .attr('stroke-width', 1.5);
                    hideTooltip();
                })
                .on('click', function(event, d) {
                    if (d.url) window.open(d.url, '_blank');
                })
                .transition()
                .duration(1000)
                .delay((d, i) => i * 5)
                .attr('r', d => sizeScale(d.onset_strength_mean));
            
            g.append('g')
                .attr('class', 'axis')
                .attr('transform', `translate(0,${height - margin.top - margin.bottom})`)
                .call(d3.axisBottom(x));
            
            g.append('g')
                .attr('class', 'axis')
                .call(d3.axisLeft(y));
            
            svg.append('text')
                .attr('x', width / 2)
                .attr('y', height - 20)
                .attr('text-anchor', 'middle')
                .attr('fill', '#e0e0e8')
                .attr('font-size', '12px')
                .text('Spectral Centroid (Brightness) - Hz');
            
            svg.append('text')
                .attr('transform', 'rotate(-90)')
                .attr('x', -height / 2)
                .attr('y', 20)
                .attr('text-anchor', 'middle')
                .attr('fill', '#e0e0e8')
                .attr('font-size', '12px')
                .text('RMS Energy');
            
            const legend = svg.append('g')
                .attr('class', 'legend')
                .attr('transform', `translate(${width - 120}, ${margin.top + 20})`);
            
            legend.append('text')
                .attr('x', 0)
                .attr('y', 0)
                .attr('fill', '#e0e0e8')
                .attr('font-weight', 'bold')
                .text('Tempo (BPM)');
            
            const legendScale = d3.scaleLinear()
                .domain([75, 165])
                .range([0, 100]);
            
            const defs = svg.append('defs');
            const legendGradient = defs.append('linearGradient')
                .attr('id', 'legend-gradient')
                .attr('x1', '0%').attr('y1', '0%')
                .attr('x2', '0%').attr('y2', '100%');
            
            legendGradient.selectAll('stop')
                .data(d3.range(0, 1.1, 0.1))
                .join('stop')
                .attr('offset', d => `${d * 100}%`)
                .attr('stop-color', d => colorScale(75 + d * 90));
            
            legend.append('rect')
                .attr('x', 0)
                .attr('y', 10)
                .attr('width', 15)
                .attr('height', 100)
                .attr('fill', 'url(#legend-gradient)');
            
            legend.append('g')
                .attr('transform', 'translate(15, 10)')
                .call(d3.axisRight(legendScale).tickValues([80, 100, 120, 140, 160]).tickSize(0))
                .select('.domain').remove();
        }
        
        function renderCorrelationViz(data) {
            const svg = d3.select('#correlation-viz');
            const width = 1000, height = 1000;
            const margin = { top: 100, right: 50, bottom: 50, left: 200 };
            const size = Math.min(width, height) - margin.left - margin.right;
            const g = svg.append('g').attr('transform', `translate(${margin.left},${margin.top})`);
            
            const features = [
                { key: 'tempo_bpm', label: 'Tempo' },
                { key: 'spectral_centroid_mean', label: 'Brightness' },
                { key: 'rms_mean', label: 'Energy' },
                { key: 'onset_strength_mean', label: 'Onset Strength' },
                { key: 'zcr_mean', label: 'Zero Crossing Rate' },
                { key: 'chroma_mean', label: 'Harmonic Content' },
                { key: 'spectral_contrast_mean', label: 'Spectral Contrast' },
                { key: 'view_count', label: 'Views' }
            ];
            
            const correlations = [];
            features.forEach(f1 => {
                features.forEach(f2 => {
                    const corr = calculateCorrelation(
                        data.map(d => d[f1.key]),
                        data.map(d => d[f2.key])
                    );
                    correlations.push({
                        x: f1.label,
                        y: f2.label,
                        value: corr
                    });
                });
            });
            
            const colorScale = d3.scaleSequential()
                .domain([-1, 1])
                .interpolator(t => {
                    if (t < 0.5) return d3.interpolateRgb('#00d4ff', '#1f1f2e')(t * 2);
                    return d3.interpolateRgb('#1f1f2e', '#ff0080')((t - 0.5) * 2);
                });
            
            const x = d3.scaleBand()
                .domain(features.map(f => f.label))
                .range([0, size])
                .padding(0.05);
            
            const y = d3.scaleBand()
                .domain(features.map(f => f.label))
                .range([0, size])
                .padding(0.05);
            
            g.selectAll('rect')
                .data(correlations)
                .join('rect')
                .attr('x', d => x(d.x))
                .attr('y', d => y(d.y))
                .attr('width', x.bandwidth())
                .attr('height', y.bandwidth())
                .attr('fill', d => colorScale(d.value))
                .attr('stroke', '#0a0a0f')
                .attr('stroke-width', 2)
                .attr('opacity', 0)
                .on('mouseover', function(event, d) {
                    d3.select(this).attr('stroke', '#00ff41').attr('stroke-width', 3);
                    showTooltip(event, `<div class="tooltip-title">${d.x} vs ${d.y}</div>
                        <div>Correlation: ${d.value.toFixed(3)}</div>`);
                })
                .on('mouseout', function() {
                    d3.select(this).attr('stroke', '#0a0a0f').attr('stroke-width', 2);
                    hideTooltip();
                })
                .transition()
                .duration(1000)
                .delay((d, i) => i * 10)
                .attr('opacity', 1);
            
            g.selectAll('text.cell-value')
                .data(correlations)
                .join('text')
                .attr('class', 'cell-value')
                .attr('x', d => x(d.x) + x.bandwidth() / 2)
                .attr('y', d => y(d.y) + y.bandwidth() / 2)
                .attr('text-anchor', 'middle')
                .attr('dominant-baseline', 'middle')
                .attr('fill', d => Math.abs(d.value) > 0.5 ? '#e0e0e8' : '#808090')
                .attr('font-size', '9px')
                .attr('font-family', 'JetBrains Mono')
                .attr('opacity', 0)
                .text(d => d.value.toFixed(2))
                .transition()
                .duration(1000)
                .delay((d, i) => i * 10 + 500)
                .attr('opacity', d => Math.abs(d.value) > 0.3 ? 1 : 0);
            
            g.append('g')
                .attr('class', 'axis')
                .call(d3.axisLeft(y).tickSize(0))
                .select('.domain').remove();
            
            g.append('g')
                .attr('class', 'axis')
                .attr('transform', `translate(0, ${size})`)
                .call(d3.axisBottom(x).tickSize(0))
                .select('.domain').remove();
            
            g.selectAll('.axis text')
                .attr('font-size', '11px')
                .attr('fill', '#e0e0e8');
            
            g.selectAll('.axis:last-of-type text')
                .attr('transform', 'rotate(-45)')
                .attr('text-anchor', 'end')
                .attr('dx', '-0.5em')
                .attr('dy', '0.5em');
        }
        
        function calculateCorrelation(x, y) {
            const n = x.length;
            const meanX = d3.mean(x);
            const meanY = d3.mean(y);
            
            let num = 0, denX = 0, denY = 0;
            for (let i = 0; i < n; i++) {
                const dx = x[i] - meanX;
                const dy = y[i] - meanY;
                num += dx * dy;
                denX += dx * dx;
                denY += dy * dy;
            }
            
            return num / Math.sqrt(denX * denY);
        }
        
        function renderArtistViz(data) {
            const svg = d3.select('#artist-viz');
            const width = 1200, height = 700;
            const margin = { top: 40, right: 40, bottom: 40, left: 40 };
            const vizWidth = width - margin.left - margin.right;
            const vizHeight = height - margin.top - margin.bottom;
            
            const g = svg.append('g').attr('transform', `translate(${margin.left},${margin.top})`);
            
            const artistData = Array.from(d3.rollup(
                data,
                v => ({
                    count: v.length,
                    avgViews: d3.mean(v, d => d.view_count),
                    totalViews: d3.sum(v, d => d.view_count),
                    avgTempo: d3.mean(v, d => d.tempo_bpm)
                }),
                d => d.uploader
            ), ([name, stats]) => ({ 
                name, 
                ...stats,
                x: vizWidth / 2 + (Math.random() - 0.5) * 100,
                y: vizHeight / 2 + (Math.random() - 0.5) * 100
            }))
            .sort((a, b) => b.count - a.count)
            .slice(0, 20);
            
            const sizeScale = d3.scaleSqrt()
                .domain(d3.extent(artistData, d => d.count))
                .range([20, 80]);
            
            const colorScale = d3.scaleSequential()
                .domain(d3.extent(artistData, d => d.avgViews))
                .interpolator(d3.interpolateRgb('#00d4ff', '#ff0080'));
            
            const nodes = g.selectAll('g.node')
                .data(artistData)
                .join('g')
                .attr('class', 'node');
            
            nodes.append('circle')
                .attr('r', d => sizeScale(d.count))
                .attr('fill', d => colorScale(d.avgViews))
                .attr('fill-opacity', 0.7)
                .attr('stroke', '#00ff41')
                .attr('stroke-width', 2)
                .style('cursor', 'pointer')
                .on('mouseover', function(event, d) {
                    d3.select(this)
                        .attr('fill-opacity', 1)
                        .attr('stroke-width', 4);
                    showTooltip(event, `<div class="tooltip-title">${d.name}</div>
                        <div>Tracks: ${d.count}</div>
                        <div>Avg Views: ${d.avgViews.toFixed(0)}</div>
                        <div>Total Views: ${d.totalViews.toLocaleString()}</div>
                        <div>Avg BPM: ${d.avgTempo.toFixed(1)}</div>
                        <div style="margin-top: 5px; color: #00d4ff; font-size: 9px;">DRAG TO MOVE</div>`);
                })
                .on('mouseout', function() {
                    d3.select(this)
                        .attr('fill-opacity', 0.7)
                        .attr('stroke-width', 2);
                    hideTooltip();
                });
            
            nodes.append('text')
                .attr('text-anchor', 'middle')
                .attr('dominant-baseline', 'middle')
                .attr('fill', '#e0e0e8')
                .attr('font-size', d => Math.max(10, sizeScale(d.count) / 3.5))
                .attr('font-weight', 'bold')
                .attr('pointer-events', 'none')
                .text(d => d.count);
            
            nodes.append('text')
                .attr('text-anchor', 'middle')
                .attr('y', d => sizeScale(d.count) + 18)
                .attr('fill', '#808090')
                .attr('font-size', '10px')
                .attr('pointer-events', 'none')
                .style('text-shadow', '0 0 3px #0a0a0f, 0 0 3px #0a0a0f')
                .text(d => {
                    const maxLen = 20;
                    return d.name.length > maxLen ? d.name.substring(0, maxLen) + '...' : d.name;
                });
            
            const simulation = d3.forceSimulation(artistData)
                .force('charge', d3.forceManyBody().strength(-300))
                .force('center', d3.forceCenter(vizWidth / 2, vizHeight / 2))
                .force('collision', d3.forceCollide().radius(d => sizeScale(d.count) + 10))
                .force('x', d3.forceX(vizWidth / 2).strength(0.05))
                .force('y', d3.forceY(vizHeight / 2).strength(0.05));
            
            simulation.on('tick', () => {
                nodes.attr('transform', d => `translate(${d.x},${d.y})`);
            });
            
            nodes.call(d3.drag()
                .on('start', dragstarted)
                .on('drag', dragged)
                .on('end', dragended));
            
            function dragstarted(event) {
                if (!event.active) simulation.alphaTarget(0.3).restart();
                event.subject.fx = event.subject.x;
                event.subject.fy = event.subject.y;
            }
            
            function dragged(event) {
                event.subject.fx = event.x;
                event.subject.fy = event.y;
            }
            
            function dragended(event) {
                if (!event.active) simulation.alphaTarget(0);
                event.subject.fx = null;
                event.subject.fy = null;
            }
        }
        
        function renderInnovationViz(data) {
            const svg = d3.select('#innovation-viz');
            const width = 1200, height = 500;
            const margin = { top: 40, right: 40, bottom: 60, left: 80 };
            const g = svg.append('g').attr('transform', `translate(${margin.left},${margin.top})`);
            
            const validData = data.filter(d => d.view_count > 0 && d.spectral_variance > 0);
            
            const x = d3.scaleLinear()
                .domain(d3.extent(validData, d => d.spectral_variance))
                .range([0, width - margin.left - margin.right])
                .nice();
            
            const y = d3.scaleLog()
                .domain([1, d3.max(validData, d => d.view_count)])
                .range([height - margin.top - margin.bottom, 0])
                .clamp(true);
            
            g.append('g')
                .attr('class', 'grid')
                .call(d3.axisLeft(y)
                    .tickSize(-(width - margin.left - margin.right))
                    .tickFormat('')
                    .ticks(5));
            
            g.append('g')
                .attr('class', 'grid')
                .attr('transform', `translate(0,${height - margin.top - margin.bottom})`)
                .call(d3.axisBottom(x)
                    .tickSize(-(height - margin.top - margin.bottom))
                    .tickFormat(''));
            
            const circles = g.selectAll('circle')
                .data(validData)
                .join('circle')
                .attr('cx', d => x(d.spectral_variance))
                .attr('cy', d => y(Math.max(1, d.view_count)))
                .attr('r', 0)
                .attr('fill', '#00ff41')
                .attr('fill-opacity', 0.5)
                .attr('stroke', '#00d4ff')
                .attr('stroke-width', 1)
                .on('mouseover', function(event, d) {
                    d3.select(this)
                        .attr('r', 8)
                        .attr('fill-opacity', 1)
                        .attr('stroke-width', 2);
                    showTooltip(event, `<div class="tooltip-title">${d.title}</div>
                        <div>Artist: ${d.uploader}</div>
                        <div>Views: ${d.view_count.toLocaleString()}</div>
                        <div>Spectral Variance: ${d.spectral_variance.toFixed(3)}</div>
                        <div>Likes: ${d.like_count}</div>
                        <div style="margin-top: 5px; color: #00d4ff; font-size: 9px;">CLICK TO OPEN ON YOUTUBE</div>`);
                })
                .on('mouseout', function() {
                    d3.select(this)
                        .attr('r', 4)
                        .attr('fill-opacity', 0.5)
                        .attr('stroke-width', 1);
                    hideTooltip();
                });
            
            circles.transition()
                .duration(1000)
                .delay((d, i) => i * 3)
                .attr('r', 4);
            
            circles.style('cursor', 'pointer')
                .on('click', function(event, d) {
                    if (d.url) window.open(d.url, '_blank');
                });
            
            try {
                const regression = linearRegression(
                    validData.map(d => d.spectral_variance),
                    validData.map(d => Math.log(Math.max(1, d.view_count)))
                );
                
                const x1 = x.domain()[0];
                const x2 = x.domain()[1];
                const y1 = Math.exp(regression.slope * x1 + regression.intercept);
                const y2 = Math.exp(regression.slope * x2 + regression.intercept);
                
                g.append('line')
                    .attr('x1', x(x1))
                    .attr('y1', y(Math.max(1, y1)))
                    .attr('x2', x(x2))
                    .attr('y2', y(Math.max(1, y2)))
                    .attr('stroke', '#ff0080')
                    .attr('stroke-width', 2)
                    .attr('stroke-dasharray', '5,5')
                    .attr('opacity', 0.6);
            } catch (error) {
                console.error('Error calculating trend line:', error);
            }
            
            g.append('g')
                .attr('class', 'axis')
                .attr('transform', `translate(0,${height - margin.top - margin.bottom})`)
                .call(d3.axisBottom(x).ticks(8));
            
            g.append('g')
                .attr('class', 'axis')
                .call(d3.axisLeft(y)
                    .ticks(5)
                    .tickFormat(d => {
                        if (d >= 1000000) return (d / 1000000).toFixed(0) + 'M';
                        if (d >= 1000) return (d / 1000).toFixed(0) + 'k';
                        return d;
                    }));
            
            svg.append('text')
                .attr('x', width / 2)
                .attr('y', height - 20)
                .attr('text-anchor', 'middle')
                .attr('fill', '#e0e0e8')
                .attr('font-size', '12px')
                .text('Spectral Variance (Sonic Experimentation)');
            
            svg.append('text')
                .attr('transform', 'rotate(-90)')
                .attr('x', -height / 2)
                .attr('y', 20)
                .attr('text-anchor', 'middle')
                .attr('fill', '#e0e0e8')
                .attr('font-size', '12px')
                .text('View Count (log scale)');
        }
        
        function linearRegression(x, y) {
            const n = x.length;
            const meanX = d3.mean(x);
            const meanY = d3.mean(y);
            
            let num = 0, den = 0;
            for (let i = 0; i < n; i++) {
                num += (x[i] - meanX) * (y[i] - meanY);
                den += (x[i] - meanX) ** 2;
            }
            
            const slope = num / den;
            const intercept = meanY - slope * meanX;
            
            return { slope, intercept };
        }
        
        function renderMFCCViz(data) {
            const svg = d3.select('#mfcc-viz');
            const width = 1200, height = 600;
            const margin = { top: 40, right: 140, bottom: 60, left: 70 };
            const g = svg.append('g').attr('transform', `translate(${margin.left},${margin.top})`);
            
            const x = d3.scaleLinear()
                .domain(d3.extent(data, d => d.mfcc1_mean))
                .range([0, width - margin.left - margin.right])
                .nice();
            
            const y = d3.scaleLinear()
                .domain(d3.extent(data, d => d.mfcc2_mean))
                .range([height - margin.top - margin.bottom, 0])
                .nice();
            
            const colorScale = d3.scaleSequential()
                .domain(d3.extent(data, d => d.tempo_bpm))
                .interpolator(d3.interpolateViridis);
            
            const sizeScale = d3.scaleSqrt()
                .domain(d3.extent(data, d => d.view_count))
                .range([3, 15]);
            
            g.append('g')
                .attr('class', 'grid')
                .call(d3.axisLeft(y).tickSize(-(width - margin.left - margin.right)).tickFormat(''));
            
            g.append('g')
                .attr('class', 'grid')
                .attr('transform', `translate(0,${height - margin.top - margin.bottom})`)
                .call(d3.axisBottom(x).tickSize(-(height - margin.top - margin.bottom)).tickFormat(''));
            
            g.selectAll('circle')
                .data(data)
                .join('circle')
                .attr('cx', d => x(d.mfcc1_mean))
                .attr('cy', d => y(d.mfcc2_mean))
                .attr('r', 0)
                .attr('fill', d => colorScale(d.tempo_bpm))
                .attr('fill-opacity', 0.6)
                .attr('stroke', d => colorScale(d.tempo_bpm))
                .attr('stroke-width', 1.5)
                .style('cursor', 'pointer')
                .on('mouseover', function(event, d) {
                    d3.select(this)
                        .attr('fill-opacity', 1)
                        .attr('stroke-width', 3)
                        .raise();
                    showTooltip(event, `<div class="tooltip-title">${d.title}</div>
                        <div>Artist: ${d.uploader}</div>
                        <div>MFCC1: ${d.mfcc1_mean.toFixed(1)}</div>
                        <div>MFCC2: ${d.mfcc2_mean.toFixed(1)}</div>
                        <div>BPM: ${d.tempo_bpm.toFixed(1)}</div>
                        <div>Views: ${d.view_count.toLocaleString()}</div>
                        <div style="margin-top: 5px; color: #00d4ff; font-size: 9px;">CLICK TO OPEN ON YOUTUBE</div>`);
                })
                .on('mouseout', function() {
                    d3.select(this)
                        .attr('fill-opacity', 0.6)
                        .attr('stroke-width', 1.5);
                    hideTooltip();
                })
                .on('click', function(event, d) {
                    if (d.url) window.open(d.url, '_blank');
                })
                .transition()
                .duration(1000)
                .delay((d, i) => i * 5)
                .attr('r', d => sizeScale(d.view_count));
            
            g.append('g')
                .attr('class', 'axis')
                .attr('transform', `translate(0,${height - margin.top - margin.bottom})`)
                .call(d3.axisBottom(x));
            
            g.append('g')
                .attr('class', 'axis')
                .call(d3.axisLeft(y));
            
            svg.append('text')
                .attr('x', width / 2)
                .attr('y', height - 20)
                .attr('text-anchor', 'middle')
                .attr('fill', '#e0e0e8')
                .attr('font-size', '12px')
                .text('MFCC 1 (Spectral Shape)');
            
            svg.append('text')
                .attr('transform', 'rotate(-90)')
                .attr('x', -height / 2)
                .attr('y', 20)
                .attr('text-anchor', 'middle')
                .attr('fill', '#e0e0e8')
                .attr('font-size', '12px')
                .text('MFCC 2 (Spectral Detail)');
        }
        
        function renderChromaViz(data) {
            const svg = d3.select('#chroma-viz');
            const width = 1200, height = 500;
            const margin = { top: 40, right: 40, bottom: 60, left: 70 };
            const g = svg.append('g').attr('transform', `translate(${margin.left},${margin.top})`);
            
            const x = d3.scaleLinear()
                .domain(d3.extent(data, d => d.chroma_mean))
                .range([0, width - margin.left - margin.right])
                .nice();
            
            const y = d3.scaleLinear()
                .domain(d3.extent(data, d => d.chroma_std))
                .range([height - margin.top - margin.bottom, 0])
                .nice();
            
            const colorScale = d3.scaleSequential()
                .domain(d3.extent(data, d => d.spectral_contrast_mean))
                .interpolator(d3.interpolatePlasma);
            
            g.append('g')
                .attr('class', 'grid')
                .call(d3.axisLeft(y).tickSize(-(width - margin.left - margin.right)).tickFormat(''));
            
            g.append('g')
                .attr('class', 'grid')
                .attr('transform', `translate(0,${height - margin.top - margin.bottom})`)
                .call(d3.axisBottom(x).tickSize(-(height - margin.top - margin.bottom)).tickFormat(''));
            
            g.selectAll('circle')
                .data(data)
                .join('circle')
                .attr('cx', d => x(d.chroma_mean))
                .attr('cy', d => y(d.chroma_std))
                .attr('r', 0)
                .attr('fill', d => colorScale(d.spectral_contrast_mean))
                .attr('fill-opacity', 0.6)
                .attr('stroke', d => colorScale(d.spectral_contrast_mean))
                .attr('stroke-width', 1.5)
                .style('cursor', 'pointer')
                .on('mouseover', function(event, d) {
                    d3.select(this)
                        .attr('fill-opacity', 1)
                        .attr('stroke-width', 3)
                        .raise();
                    showTooltip(event, `<div class="tooltip-title">${d.title}</div>
                        <div>Chroma Mean: ${d.chroma_mean.toFixed(3)}</div>
                        <div>Chroma Std: ${d.chroma_std.toFixed(3)}</div>
                        <div>Spectral Contrast: ${d.spectral_contrast_mean.toFixed(1)}</div>
                        <div>BPM: ${d.tempo_bpm.toFixed(1)}</div>
                        <div style="margin-top: 5px; color: #00d4ff; font-size: 9px;">CLICK TO OPEN ON YOUTUBE</div>`);
                })
                .on('mouseout', function() {
                    d3.select(this)
                        .attr('fill-opacity', 0.6)
                        .attr('stroke-width', 1.5);
                    hideTooltip();
                })
                .on('click', function(event, d) {
                    if (d.url) window.open(d.url, '_blank');
                })
                .transition()
                .duration(1000)
                .delay((d, i) => i * 5)
                .attr('r', 5);
            
            g.append('g')
                .attr('class', 'axis')
                .attr('transform', `translate(0,${height - margin.top - margin.bottom})`)
                .call(d3.axisBottom(x));
            
            g.append('g')
                .attr('class', 'axis')
                .call(d3.axisLeft(y));
            
            svg.append('text')
                .attr('x', width / 2)
                .attr('y', height - 20)
                .attr('text-anchor', 'middle')
                .attr('fill', '#e0e0e8')
                .attr('font-size', '12px')
                .text('Chroma Mean (Harmonic Content)');
            
            svg.append('text')
                .attr('transform', 'rotate(-90)')
                .attr('x', -height / 2)
                .attr('y', 20)
                .attr('text-anchor', 'middle')
                .attr('fill', '#e0e0e8')
                .attr('font-size', '12px')
                .text('Chroma Std (Harmonic Variation)');
        }
        
        function renderSpectralProfileViz(data) {
            const svg = d3.select('#spectral-profile-viz');
            const width = 1200, height = 600;
            const margin = { top: 40, right: 140, bottom: 60, left: 70 };
            const g = svg.append('g').attr('transform', `translate(${margin.left},${margin.top})`);
            
            const x = d3.scaleLinear()
                .domain(d3.extent(data, d => d.spectral_bandwidth_mean))
                .range([0, width - margin.left - margin.right])
                .nice();
            
            const y = d3.scaleLinear()
                .domain(d3.extent(data, d => d.spectral_rolloff_mean))
                .range([height - margin.top - margin.bottom, 0])
                .nice();
            
            const colorScale = d3.scaleSequential()
                .domain([75, 165])
                .interpolator(d3.interpolateTurbo);
            
            const sizeScale = d3.scaleSqrt()
                .domain(d3.extent(data, d => d.rms_mean))
                .range([3, 15]);
            
            g.append('g')
                .attr('class', 'grid')
                .call(d3.axisLeft(y).tickSize(-(width - margin.left - margin.right)).tickFormat(''));
            
            g.append('g')
                .attr('class', 'grid')
                .attr('transform', `translate(0,${height - margin.top - margin.bottom})`)
                .call(d3.axisBottom(x).tickSize(-(height - margin.top - margin.bottom)).tickFormat(''));
            
            g.selectAll('circle')
                .data(data)
                .join('circle')
                .attr('cx', d => x(d.spectral_bandwidth_mean))
                .attr('cy', d => y(d.spectral_rolloff_mean))
                .attr('r', 0)
                .attr('fill', d => colorScale(d.tempo_bpm))
                .attr('fill-opacity', 0.6)
                .attr('stroke', d => colorScale(d.tempo_bpm))
                .attr('stroke-width', 1.5)
                .style('cursor', 'pointer')
                .on('mouseover', function(event, d) {
                    d3.select(this)
                        .attr('fill-opacity', 1)
                        .attr('stroke-width', 3)
                        .raise();
                    showTooltip(event, `<div class="tooltip-title">${d.title}</div>
                        <div>Bandwidth: ${d.spectral_bandwidth_mean.toFixed(0)} Hz</div>
                        <div>Rolloff: ${d.spectral_rolloff_mean.toFixed(0)} Hz</div>
                        <div>Energy: ${d.rms_mean.toFixed(3)}</div>
                        <div>BPM: ${d.tempo_bpm.toFixed(1)}</div>
                        <div style="margin-top: 5px; color: #00d4ff; font-size: 9px;">CLICK TO OPEN ON YOUTUBE</div>`);
                })
                .on('mouseout', function() {
                    d3.select(this)
                        .attr('fill-opacity', 0.6)
                        .attr('stroke-width', 1.5);
                    hideTooltip();
                })
                .on('click', function(event, d) {
                    if (d.url) window.open(d.url, '_blank');
                })
                .transition()
                .duration(1000)
                .delay((d, i) => i * 5)
                .attr('r', d => sizeScale(d.rms_mean));
            
            g.append('g')
                .attr('class', 'axis')
                .attr('transform', `translate(0,${height - margin.top - margin.bottom})`)
                .call(d3.axisBottom(x));
            
            g.append('g')
                .attr('class', 'axis')
                .call(d3.axisLeft(y));
            
            svg.append('text')
                .attr('x', width / 2)
                .attr('y', height - 20)
                .attr('text-anchor', 'middle')
                .attr('fill', '#e0e0e8')
                .attr('font-size', '12px')
                .text('Spectral Bandwidth (Frequency Spread) - Hz');
            
            svg.append('text')
                .attr('transform', 'rotate(-90)')
                .attr('x', -height / 2)
                .attr('y', 20)
                .attr('text-anchor', 'middle')
                .attr('fill', '#e0e0e8')
                .attr('font-size', '12px')
                .text('Spectral Rolloff (Frequency Weight) - Hz');
        }
        
        function renderRhythmViz(data) {
            const svg = d3.select('#rhythm-viz');
            const width = 1200, height = 500;
            const margin = { top: 40, right: 40, bottom: 60, left: 70 };
            const g = svg.append('g').attr('transform', `translate(${margin.left},${margin.top})`);
            
            const x = d3.scaleLinear()
                .domain(d3.extent(data, d => d.onset_strength_mean))
                .range([0, width - margin.left - margin.right])
                .nice();
            
            const histogram = d3.histogram()
                .domain(x.domain())
                .thresholds(x.ticks(30))
                .value(d => d.onset_strength_mean);
            
            const bins = histogram(data);
            
            const y = d3.scaleLinear()
                .domain([0, d3.max(bins, d => d.length)])
                .range([height - margin.top - margin.bottom, 0]);
            
            g.append('g')
                .attr('class', 'grid')
                .call(d3.axisLeft(y).tickSize(-(width - margin.left - margin.right)).tickFormat(''));
            
            const defs = svg.select('defs').empty() ? svg.append('defs') : svg.select('defs');
            const gradient = defs.append('linearGradient')
                .attr('id', 'rhythm-gradient')
                .attr('x1', '0%').attr('y1', '0%')
                .attr('x2', '100%').attr('y2', '0%');
            
            gradient.append('stop')
                .attr('offset', '0%')
                .attr('stop-color', '#00d4ff')
                .attr('stop-opacity', 0.8);
            
            gradient.append('stop')
                .attr('offset', '50%')
                .attr('stop-color', '#00ff41')
                .attr('stop-opacity', 0.8);
            
            gradient.append('stop')
                .attr('offset', '100%')
                .attr('stop-color', '#ff0080')
                .attr('stop-opacity', 0.8);
            
            g.selectAll('rect')
                .data(bins)
                .join('rect')
                .attr('x', d => x(d.x0) + 1)
                .attr('y', height - margin.top - margin.bottom)
                .attr('width', d => Math.max(0, x(d.x1) - x(d.x0) - 2))
                .attr('height', 0)
                .attr('fill', 'url(#rhythm-gradient)')
                .attr('stroke', '#00ff41')
                .attr('stroke-width', 0.5)
                .on('mouseover', function(event, d) {
                    d3.select(this).attr('opacity', 0.7);
                    const avgTempo = d3.mean(d, track => track.tempo_bpm);
                    showTooltip(event, `<div class="tooltip-title">Onset: ${d.x0.toFixed(2)}-${d.x1.toFixed(2)}</div>
                        <div>${d.length} tracks</div>
                        <div>Avg BPM: ${avgTempo ? avgTempo.toFixed(1) : 'N/A'}</div>`);
                })
                .on('mouseout', function() {
                    d3.select(this).attr('opacity', 1);
                    hideTooltip();
                })
                .transition()
                .duration(1000)
                .delay((d, i) => i * 20)
                .attr('y', d => y(d.length))
                .attr('height', d => height - margin.top - margin.bottom - y(d.length));
            
            g.append('g')
                .attr('class', 'axis')
                .attr('transform', `translate(0,${height - margin.top - margin.bottom})`)
                .call(d3.axisBottom(x));
            
            g.append('g')
                .attr('class', 'axis')
                .call(d3.axisLeft(y));
            
            svg.append('text')
                .attr('x', width / 2)
                .attr('y', height - 20)
                .attr('text-anchor', 'middle')
                .attr('fill', '#e0e0e8')
                .attr('font-size', '12px')
                .text('Onset Strength (Rhythmic Intensity)');
            
            svg.append('text')
                .attr('transform', 'rotate(-90)')
                .attr('x', -height / 2)
                .attr('y', 20)
                .attr('text-anchor', 'middle')
                .attr('fill', '#e0e0e8')
                .attr('font-size', '12px')
                .text('Track Count');
        }
        
        function renderZCRViz(data) {
            const svg = d3.select('#zcr-viz');
            const width = 1200, height = 600;
            const margin = { top: 40, right: 140, bottom: 60, left: 70 };
            const g = svg.append('g').attr('transform', `translate(${margin.left},${margin.top})`);
            
            const x = d3.scaleLinear()
                .domain(d3.extent(data, d => d.zcr_mean))
                .range([0, width - margin.left - margin.right])
                .nice();
            
            const y = d3.scaleLinear()
                .domain(d3.extent(data, d => d.spectral_bandwidth_mean))
                .range([height - margin.top - margin.bottom, 0])
                .nice();
            
            const colorScale = d3.scaleSequential()
                .domain(d3.extent(data, d => d.rms_mean))
                .interpolator(d3.interpolateCool);
            
            const sizeScale = d3.scaleSqrt()
                .domain(d3.extent(data, d => d.onset_strength_mean))
                .range([3, 15]);
            
            g.append('g')
                .attr('class', 'grid')
                .call(d3.axisLeft(y).tickSize(-(width - margin.left - margin.right)).tickFormat(''));
            
            g.append('g')
                .attr('class', 'grid')
                .attr('transform', `translate(0,${height - margin.top - margin.bottom})`)
                .call(d3.axisBottom(x).tickSize(-(height - margin.top - margin.bottom)).tickFormat(''));
            
            g.selectAll('circle')
                .data(data)
                .join('circle')
                .attr('cx', d => x(d.zcr_mean))
                .attr('cy', d => y(d.spectral_bandwidth_mean))
                .attr('r', 0)
                .attr('fill', d => colorScale(d.rms_mean))
                .attr('fill-opacity', 0.6)
                .attr('stroke', d => colorScale(d.rms_mean))
                .attr('stroke-width', 1.5)
                .style('cursor', 'pointer')
                .on('mouseover', function(event, d) {
                    d3.select(this)
                        .attr('fill-opacity', 1)
                        .attr('stroke-width', 3)
                        .raise();
                    showTooltip(event, `<div class="tooltip-title">${d.title}</div>
                        <div>ZCR: ${d.zcr_mean.toFixed(4)}</div>
                        <div>Bandwidth: ${d.spectral_bandwidth_mean.toFixed(0)} Hz</div>
                        <div>Energy: ${d.rms_mean.toFixed(3)}</div>
                        <div>Onset: ${d.onset_strength_mean.toFixed(2)}</div>
                        <div style="margin-top: 5px; color: #00d4ff; font-size: 9px;">CLICK TO OPEN ON YOUTUBE</div>`);
                })
                .on('mouseout', function() {
                    d3.select(this)
                        .attr('fill-opacity', 0.6)
                        .attr('stroke-width', 1.5);
                    hideTooltip();
                })
                .on('click', function(event, d) {
                    if (d.url) window.open(d.url, '_blank');
                })
                .transition()
                .duration(1000)
                .delay((d, i) => i * 5)
                .attr('r', d => sizeScale(d.onset_strength_mean));
            
            g.append('g')
                .attr('class', 'axis')
                .attr('transform', `translate(0,${height - margin.top - margin.bottom})`)
                .call(d3.axisBottom(x).tickFormat(d3.format('.3f')));
            
            g.append('g')
                .attr('class', 'axis')
                .call(d3.axisLeft(y));
            
            svg.append('text')
                .attr('x', width / 2)
                .attr('y', height - 20)
                .attr('text-anchor', 'middle')
                .attr('fill', '#e0e0e8')
                .attr('font-size', '12px')
                .text('Zero-Crossing Rate (Percussive Content)');
            
            svg.append('text')
                .attr('transform', 'rotate(-90)')
                .attr('x', -height / 2)
                .attr('y', 20)
                .attr('text-anchor', 'middle')
                .attr('fill', '#e0e0e8')
                .attr('font-size', '12px')
                .text('Spectral Bandwidth (Hz)');
        }
        
        function renderParallelViz(data) {
            const svg = d3.select('#parallel-viz');
            const width = 1200, height = 700;
            const margin = { top: 60, right: 40, bottom: 40, left: 40 };
            const g = svg.append('g').attr('transform', `translate(${margin.left},${margin.top})`);
            
            const features = [
                { key: 'tempo_bpm', label: 'Tempo' },
                { key: 'spectral_centroid_mean', label: 'Brightness' },
                { key: 'rms_mean', label: 'Energy' },
                { key: 'onset_strength_mean', label: 'Onset' },
                { key: 'zcr_mean', label: 'ZCR' },
                { key: 'chroma_mean', label: 'Chroma' },
                { key: 'spectral_contrast_mean', label: 'Contrast' }
            ];
            
            const normalized = data.map(d => {
                const norm = { ...d };
                features.forEach(f => {
                    const extent = d3.extent(data, track => track[f.key]);
                    norm[f.key + '_norm'] = (d[f.key] - extent[0]) / (extent[1] - extent[0]);
                });
                return norm;
            });
            
            const x = d3.scalePoint()
                .domain(features.map(f => f.key))
                .range([0, width - margin.left - margin.right]);
            
            const y = d3.scaleLinear()
                .domain([0, 1])
                .range([height - margin.top - margin.bottom, 0]);
            
            const colorScale = d3.scaleSequential()
                .domain([75, 165])
                .interpolator(d3.interpolateRainbow);
            
            const line = d3.line()
                .x((d, i) => x(features[i].key))
                .y(d => y(d));
            
            g.selectAll('path.parallel-line')
                .data(normalized)
                .join('path')
                .attr('class', 'parallel-line')
                .attr('d', d => line(features.map(f => d[f.key + '_norm'])))
                .attr('fill', 'none')
                .attr('stroke', d => colorScale(d.tempo_bpm))
                .attr('stroke-width', 0.5)
                .attr('opacity', 0.3)
                .style('cursor', 'pointer')
                .on('mouseover', function(event, d) {
                    d3.select(this)
                        .attr('stroke-width', 3)
                        .attr('opacity', 1)
                        .raise();
                    showTooltip(event, `<div class="tooltip-title">${d.title}</div>
                        <div>BPM: ${d.tempo_bpm.toFixed(1)}</div>
                        <div>Artist: ${d.uploader}</div>
                        <div style="margin-top: 5px; color: #00d4ff; font-size: 9px;">CLICK TO OPEN ON YOUTUBE</div>`);
                })
                .on('mouseout', function() {
                    d3.select(this)
                        .attr('stroke-width', 0.5)
                        .attr('opacity', 0.3);
                    hideTooltip();
                })
                .on('click', function(event, d) {
                    if (d.url) window.open(d.url, '_blank');
                });
            
            features.forEach(f => {
                const extent = d3.extent(data, d => d[f.key]);
                const axisScale = d3.scaleLinear()
                    .domain(extent)
                    .range([height - margin.top - margin.bottom, 0]);
                
                const axis = g.append('g')
                    .attr('class', 'axis')
                    .attr('transform', `translate(${x(f.key)},0)`)
                    .call(d3.axisLeft(axisScale).ticks(5));
                
                axis.append('text')
                    .attr('y', -20)
                    .attr('text-anchor', 'middle')
                    .attr('fill', '#00ff41')
                    .attr('font-size', '12px')
                    .attr('font-weight', 'bold')
                    .text(f.label);
            });
        }
        
        function showTooltip(event, content) {
            const tooltip = d3.select('#tooltip');
            tooltip.html(content)
                .style('left', (event.pageX + 10) + 'px')
                .style('top', (event.pageY - 10) + 'px')
                .style('opacity', 1);
        }
        
        function hideTooltip() {
            d3.select('#tooltip').style('opacity', 0);
        }
    </script>
</body>
</html>
